import os
import json
import time
import re
import requests
import sys
from datetime import datetime
from playwright.sync_api import sync_playwright

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
DEFAULT_URL = "https://sm.rakuten.co.jp/search/200029"

# [ìˆ˜ì • 3] ìˆ˜ì§‘í•  í˜ì´ì§€ êµ¬ê°„ ì„¤ì • (ì˜ˆ: 2í˜ì´ì§€ë¶€í„° 5í˜ì´ì§€ê¹Œì§€)
START_PAGE = 1
MAX_PAGES = 99

IMAGE_DIR = "images"
NAV_TIMEOUT_MS = 30000
LIST_TIMEOUT_MS = 15000
NAV_RETRIES = 2

# [ìˆ˜ì • 2] íŒŒì¼ëª…ì— ì‹œ/ë¶„/ì´ˆ ì¶”ê°€ (ì˜ˆ: 20240208_153022_products.json)
current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
DATA_FILE = f"{current_time}_products.json"

if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

# ==========================================
# 2. í—¬í¼ í•¨ìˆ˜
# ==========================================
def clean_text(text):
    """í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text: return "Unknown"
    return text.strip().replace("\n", "").replace("\t", "")

def get_high_res_url(img_url):
    """ê³ í•´ìƒë„ ì´ë¯¸ì§€ URL ë³€í™˜ ë° https í”„ë¡œí† ì½œ ì¶”ê°€"""
    if not img_url: return ""
    if img_url.startswith("//"):
        img_url = "https:" + img_url
    return img_url.split("?")[0]

def download_image(url, filename):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    if not url: return False
    if url.startswith("//"):
        url = "https:" + url
        
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            with open(os.path.join(IMAGE_DIR, filename), 'wb') as f:
                f.write(response.content)
            return True
    except Exception:
        pass
    return False

def navigate_and_wait(page, url):
    """í˜ì´ì§€ ì´ë™ í›„ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ê°€ ë³´ì¼ ë•Œê¹Œì§€ ëŒ€ê¸° (ì¬ì‹œë„ í¬í•¨)."""
    last_error = None
    for attempt in range(1, NAV_RETRIES + 1):
        try:
            page.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT_MS)
            page.wait_for_selector("#item-list .product-item", timeout=LIST_TIMEOUT_MS)
            return True
        except Exception as e:
            last_error = e
            print(f"   âš ï¸ ë¡œë”© ì§€ì—°ìœ¼ë¡œ ì¬ì‹œë„ {attempt}/{NAV_RETRIES}: {e}")
            time.sleep(2)
    print(f"   âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {last_error}")
    return False

# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def run():
    # URL ì¸ì ì²˜ë¦¬
    target_urls = sys.argv[1:]
    if not target_urls:
        print("â„¹ï¸ ì…ë ¥ëœ URLì´ ì—†ì–´ ê¸°ë³¸ ë¼ë©´ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        target_urls = [DEFAULT_URL]
    
    print(f"ğŸš€ Rakuten Seiyu í¬ë¡¤ëŸ¬ v7.0 ì‹œì‘... (ì´ {len(target_urls)}ê°œ URL)")
    print(f"ğŸ“„ ìˆ˜ì§‘ êµ¬ê°„: {START_PAGE}í˜ì´ì§€ ~ {MAX_PAGES}í˜ì´ì§€")
    print(f"ğŸ“ ì €ì¥ íŒŒì¼ëª…: {DATA_FILE}")

    with sync_playwright() as p:
        # Stealth ëª¨ë“œ: ë´‡ ê°ì§€ ìš°íšŒë¥¼ ìœ„í•œ ì„¤ì •
        browser = p.chromium.launch(
            headless=False,
            args=[
                "--disable-blink-features=AutomationControlled",
                "--disable-dev-shm-usage",
                "--no-sandbox",
            ]
        )
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={"width": 1920, "height": 1080},
            locale="ja-JP",
            timezone_id="Asia/Tokyo",
        )
        
        # navigator.webdriverë¥¼ falseë¡œ ì„¤ì • (ë´‡ ê°ì§€ ìš°íšŒ í•µì‹¬)
        context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            Object.defineProperty(navigator, 'languages', {
                get: () => ['ja-JP', 'ja', 'en-US', 'en']
            });
            window.chrome = { runtime: {} };
        """)
        
        page = context.new_page()

        all_products_total = []

        # --- ì…ë ¥ëœ URL ìˆœíšŒ ---
        for url_idx, target_url in enumerate(target_urls):
            print(f"\n==========================================")
            print(f"ğŸŒ [{url_idx+1}/{len(target_urls)}] íƒ€ê²Ÿ URL ì²˜ë¦¬ ì¤‘...")
            print(f"ğŸ”— {target_url}")
            print(f"==========================================")
            
            # ì‹œì‘ í˜ì´ì§€ë¡œ ì´ë™ (START_PAGEê°€ 1ì´ë©´ ì›ë³¸ URL, ì•„ë‹ˆë©´ ?page=N ì¶”ê°€)
            if START_PAGE == 1:
                start_url = target_url
            else:
                separator = "&" if "?" in target_url else "?"
                start_url = f"{target_url}{separator}page={START_PAGE}"
            
            print(f"\nğŸ“„ {START_PAGE}í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...")
            if not navigate_and_wait(page, start_url):
                print("   âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨, ë‹¤ìŒ URLë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                continue

            # ì‹¤ì œ ìˆ˜ì§‘ ì‹œì‘
            for current_page in range(START_PAGE, MAX_PAGES + 1):
                print(f"\nğŸ“„ {current_page}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")

                # START_PAGE ì´í›„ í˜ì´ì§€ëŠ” ë‹¤ìŒ ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ì´ë™
                if current_page > START_PAGE:
                    next_link = page.locator(".paging .paging-next-page a")
                    if next_link.count() == 0:
                        print("   âš ï¸ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë§ˆì§€ë§‰ í˜ì´ì§€)")
                        break
                    
                    current_first_id = ""
                    first_item = page.locator("#item-list .product-item").first
                    if first_item.count() > 0:
                        current_first_id = first_item.get_attribute("data-ratid") or ""
                    
                    next_link.first.click()
                    
                    page_changed = False
                    for wait_sec in range(15):
                        time.sleep(1)
                        new_first_item = page.locator("#item-list .product-item").first
                        if new_first_item.count() > 0:
                            new_first_id = new_first_item.get_attribute("data-ratid") or ""
                            if new_first_id and new_first_id != current_first_id:
                                page_changed = True
                                break
                        print(f"   â³ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°... {wait_sec+1}ì´ˆ")
                    
                    if not page_changed:
                        print("   âŒ í˜ì´ì§€ ì „í™˜ ì‹¤íŒ¨ (íƒ€ì„ì•„ì›ƒ)")
                        break

                time.sleep(1) # ë Œë”ë§ ì•ˆì •í™” ëŒ€ê¸°

                # ìŠ¤í¬ë¡¤ (ì´ë¯¸ì§€ ë¡œë”© íŠ¸ë¦¬ê±°)
                page.mouse.wheel(0, 4000)
                time.sleep(1)

                # --- ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ---
                category = "Unknown"
                try:
                    cat_el = page.locator('xpath=//*[@id="container"]/div[1]/div/div/div[3]/h1')
                    if cat_el.count() > 0:
                        raw_cat = clean_text(cat_el.first.inner_text())
                        category = re.sub(r'\s*\d+ï½\d+ä»¶.*', '', raw_cat).strip()
                except Exception:
                    pass

                # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
                products = page.locator("#item-list .product-item:not(.product-item-next)")
                count = products.count()
                print(f"   -> {count}ê°œ ìƒí’ˆ ë°œê²¬ (ì¹´í…Œê³ ë¦¬: {category})")

                if count == 0:
                    print("   âš ï¸ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. (í˜ì´ì§€ ë ë„ë‹¬ ê°€ëŠ¥ì„±)")
                    break

                # --- ìƒí’ˆ ìˆœíšŒ ---
                for i in range(count):
                    try:
                        item = products.nth(i)
                        
                        # 1. ê¸°ë³¸ ì •ë³´
                        maker_el = item.locator(".product-item-info-maker")
                        maker = clean_text(maker_el.inner_text()) if maker_el.count() > 0 else "Unknown"

                        name_el = item.locator(".product-item-info-name")
                        name = clean_text(name_el.inner_text()) if name_el.count() > 0 else "Unknown"

                        price_el = item.locator(".product-item-info-price")
                        price_text = price_el.inner_text() if price_el.count() > 0 else "0"
                        price = re.sub(r'[^0-9]', '', price_text)

                        # 2. ID ì¶”ì¶œ
                        item_id = item.get_attribute("data-ratid")
                        if not item_id:
                            link_el = item.locator("a").first
                            href = link_el.get_attribute("href")
                            match = re.search(r'/item/(\d+)', href)
                            item_id = match.group(1) if match else f"unknown_{i}"

                        # 3. ì œí’ˆ URL
                        product_url = ""
                        link_el = item.locator("a").first
                        if link_el.count() > 0:
                            href = link_el.get_attribute("href")
                            if href:
                                if href.startswith("/"):
                                    product_url = f"https://sm.rakuten.co.jp{href}"
                                else:
                                    product_url = href

                        # 4. ì´ë¯¸ì§€ URL
                        img_el = item.locator("img.img-base-size")
                        raw_img_url = ""
                        if img_el.count() > 0:
                            raw_img_url = img_el.get_attribute("data-src") or img_el.get_attribute("src")
                        
                        final_img_url = get_high_res_url(raw_img_url)

                        # ë°ì´í„° ì €ì¥
                        product_data = {
                            "id": item_id,
                            "category": category,
                            "maker": maker,
                            "name": name,
                            "price": int(price) if price else 0,
                            "product_url": product_url,
                            "image_url": final_img_url,
                            "page": current_page,
                            "source_url": target_url
                        }
                        all_products_total.append(product_data)
                        
                        print(f"   [{i+1}/{count}] {item_id} | {name[:10]}... | {category}")

                        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                        if final_img_url:
                            safe_name = re.sub(r'[\\/*?:"<>|]', "", name).replace(" ", "_")
                            safe_maker = re.sub(r'[\\/*?:"<>|]', "", maker).replace(" ", "_")
                            ext = ".png" if ".png" in final_img_url else ".jpg"
                            filename = f"{item_id}_{safe_maker}_{safe_name[:20]}{ext}"
                            download_image(final_img_url, filename)

                    except Exception as e:
                        print(f"   âŒ {i}ë²ˆ ì—ëŸ¬: {e}")
                        continue
        
        # íŒŒì¼ ì €ì¥
        with open(DATA_FILE, "w", encoding="utf-8") as f:
            json.dump(all_products_total, f, ensure_ascii=False, indent=4)
        
        print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print(f"   âœ… ì´ ë°ì´í„°: {len(all_products_total)}ê°œ")
        print(f"   âœ… íŒŒì¼ëª…: {DATA_FILE}")
        
        browser.close()

if __name__ == "__main__":
    run()